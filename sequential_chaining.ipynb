{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPGlYocpAUJhwTT/dCZJcnp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/uguazelli/langchain/blob/main/sequential_chaining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sequential Chaining (Multi-Step Prompting)\n",
        "Use multi-step chaining if:\n",
        "* You need very reliable results\n",
        "* You want to inject logic or validation between steps\n",
        "* You're building an agent or a dynamic flow"
      ],
      "metadata": {
        "id": "pXUPB1N-Wq31"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pip Install"
      ],
      "metadata": {
        "id": "fshoYtRPIUSI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install -U langchain langchain-community langchain-openai\n",
        "!pip install pydantic\n"
      ],
      "metadata": {
        "id": "Wpx5QpG8MMwN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a723cb5-100a-4340-8e80-7352ccc7a0df"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.3.26-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.26-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.3.24-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting langchain-core<1.0.0,>=0.3.66 (from langchain)\n",
            "  Downloading langchain_core-0.3.66-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.45)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.10.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.86.0 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.86.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.9.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (4.14.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.6.15)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain-0.3.26-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.26-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.3.24-py3-none-any.whl (68 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m69.0/69.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langchain_core-0.3.66-py3-none-any.whl (438 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m438.9/438.9 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.10.0-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-core, langchain-openai, langchain, langchain-community\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.65\n",
            "    Uninstalling langchain-core-0.3.65:\n",
            "      Successfully uninstalled langchain-core-0.3.65\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.25\n",
            "    Uninstalling langchain-0.3.25:\n",
            "      Successfully uninstalled langchain-0.3.25\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-0.3.26 langchain-community-0.3.26 langchain-core-0.3.66 langchain-openai-0.3.24 marshmallow-3.26.1 mypy-extensions-1.1.0 pydantic-settings-2.10.0 python-dotenv-1.1.0 typing-inspect-0.9.0\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (2.11.7)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic) (4.14.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic) (0.4.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "zZC400R5IYQk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JKD2nukCIeWY"
      },
      "outputs": [],
      "source": [
        "# Imports'\n",
        "from google.colab import userdata\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_openai import OpenAI # âœ… use langchain_openai, not community\n",
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from pydantic import BaseModel, Field\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get API key from Colab secrets\n",
        "api_key = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "FEfmiyaPKSuY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define LLM (completion model like GPT-3.5-turbo-instruct and level of creativity 0.6 of 1)\n",
        "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\", api_key=api_key, temperature=0.6)"
      ],
      "metadata": {
        "id": "Mh1Rk_yBLyMP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test simple call\n",
        "response = llm.invoke(\"Tell me a fun fact about AI\")\n",
        "print(\"Simple Response:\", response)"
      ],
      "metadata": {
        "id": "ye_QVrUgRQZA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9377edcf-f7e6-4439-e607-cd726b922258"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Simple Response: \n",
            "\n",
            "One fun fact about AI is that it can learn and improve itself without human intervention. This is known as \"machine learning\" and it allows AI to continuously adapt and become more efficient at completing tasks. Another fun fact is that AI has been used to create original artworks and even a novel, showing its creative potential. Additionally, AI is being used in video games to create more realistic and challenging opponents for players.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Name\n",
        "name_prompt = PromptTemplate.from_template(\n",
        "    \"I want to open a {topic} restaurant. Suggest a really nice name. Return just one name.\"\n",
        ")\n",
        "\n",
        "# Step 2: Slogan\n",
        "slogan_prompt = PromptTemplate.from_template(\n",
        "    \"Create a catchy slogan for a restaurant named '{name}'.\"\n",
        ")\n",
        "\n",
        "# Step 3: Concept\n",
        "concept_prompt = PromptTemplate.from_template(\n",
        "    \"Describe the branding and interior design concept for a restaurant named '{name}' with the slogan '{slogan}'.\"\n",
        ")\n",
        "\n",
        "# Step 4: Logo Description\n",
        "logo_prompt = PromptTemplate.from_template(\n",
        "    \"Based on the name '{name}' and slogan '{slogan}', describe an ideal logo: colors, icon, font, and style.\"\n",
        ")\n",
        "\n",
        "# Step 5: Image Generation Prompt (for DALLÂ·E or Midjourney)\n",
        "image_prompt = PromptTemplate.from_template(\n",
        "    \"Create a visual prompt for an image generation tool to design the logo: '{logo_description}'\"\n",
        ")"
      ],
      "metadata": {
        "id": "0PthmDMcVA0Z"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build each step\n",
        "step1 = name_prompt | llm\n",
        "step2 = lambda name: slogan_prompt | llm\n",
        "step3 = lambda name, slogan: concept_prompt | llm\n",
        "step4 = lambda name, slogan: logo_prompt | llm\n",
        "step5 = lambda logo_description: image_prompt | llm"
      ],
      "metadata": {
        "id": "JD2XE-QLe347"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Wrap in RunnableSequence\n",
        "def full_pipeline(topic: str):\n",
        "    name = step1.invoke({\"topic\": topic}).strip()\n",
        "    slogan = (slogan_prompt | llm).invoke({\"name\": name}).strip()\n",
        "    concept = (concept_prompt | llm).invoke({\"name\": name, \"slogan\": slogan}).strip()\n",
        "    logo = (logo_prompt | llm).invoke({\"name\": name, \"slogan\": slogan}).strip()\n",
        "    image_prompt_text = (image_prompt | llm).invoke({\"logo_description\": logo}).strip()\n",
        "\n",
        "    return {\n",
        "        \"name\": name,\n",
        "        \"slogan\": slogan,\n",
        "        \"concept\": concept,\n",
        "        \"logo_description\": logo,\n",
        "        \"image_prompt\": image_prompt_text\n",
        "    }"
      ],
      "metadata": {
        "id": "viWHxJrbe_9k"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run\n",
        "result = full_pipeline(\"Brazilian\")\n",
        "for key, value in result.items():\n",
        "    print(f\"\\nðŸ”¹ {key.upper()}:\\n{value}\")"
      ],
      "metadata": {
        "id": "JC5GnQ6dfFq8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca7aa0f1-6418-4577-9a2a-03d86840c2aa"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ”¹ NAME:\n",
            "Fogo de ChÃ£o\n",
            "\n",
            "ðŸ”¹ SLOGAN:\n",
            "\"Savor the fire, taste the passion at Fogo de ChÃ£o.\"\n",
            "\n",
            "ðŸ”¹ CONCEPT:\n",
            "Branding Concept:\n",
            "The branding concept for Fogo de ChÃ£o is centered around the idea of fire and passion. The name itself, which translates to \"fire of the ground\" in Portuguese, evokes images of a traditional Brazilian churrascaria, where meats are cooked over an open flame. The logo for Fogo de ChÃ£o features a stylized flame, with bold and vibrant colors, representing the passion and energy of Brazilian culture. The slogan, \"Savor the fire, taste the passion at Fogo de ChÃ£o,\" further reinforces this concept, inviting customers to experience the fiery and passionate flavors of Brazil at the restaurant.\n",
            "\n",
            "Interior Design Concept:\n",
            "The interior design of Fogo de ChÃ£o is inspired by the rustic and warm atmosphere of traditional Brazilian churrascarias. The main dining area features a mix of warm earth tones and natural materials, such as wood and stone, creating a cozy and inviting ambiance. The walls are adorned with Brazilian artwork, showcasing the country's vibrant culture and adding a touch of authenticity to the space.\n",
            "\n",
            "The focal point of the restaurant is the open kitchen, where customers can see the skilled chefs cooking the meats over an open flame. This not only adds to the overall atmosphere but also highlights the restaurant's focus on fire-grilled meats\n",
            "\n",
            "ðŸ”¹ LOGO_DESCRIPTION:\n",
            "The ideal logo for Fogo de ChÃ£o would be bold and fiery, reflecting the passion and flavor of the brand. The color scheme would consist of warm, bold colors such as red, orange, and gold to represent the fire element. The logo would feature an icon of a flame or fire, symbolizing the churrasco-style grilling that is a signature of Fogo de ChÃ£o. The font would be strong and elegant, with a slight curve to add a touch of sophistication. The style would be clean and modern, with a touch of Brazilian flair. Overall, the logo would convey a sense of energy, warmth, and excitement that captures the essence of Fogo de ChÃ£o.\n",
            "\n",
            "ðŸ”¹ IMAGE_PROMPT:\n",
            "The visual prompt could be an image of a bright, fiery flame with bold, warm colors surrounding it. The flame could be set against a clean, modern background with subtle hints of Brazilian design elements. The font used for the text \"Fogo de ChÃ£o\" could be strong and elegant, with a slight curve to add a touch of sophistication. The overall composition should evoke a sense of energy and excitement, while also conveying the brand's passion and flavor.\n"
          ]
        }
      ]
    }
  ]
}